import random
from typing import Tuple

import cv2
import numpy as np

from 任务流程.基础任务框架 import 基础任务, 任务上下文
from 任务流程.速度刷资源.进攻坐标逻辑计算 import 取进攻方向, 坐标, 取可下兵坐标点, 判断目标点到可进攻边缘距离是否小于设定值
from 模块.检测.OCR识别器 import 安全OCR引擎
from 模块.检测.YOLO检测器 import 线程安全YOLO检测器
from 模块.检测.模板匹配器 import 模板匹配引擎
from 任务流程.保存截图 import 截图保存工具


class 进攻任务(基础任务):
    # 配置常量
    兵种模板列表 = [
        "兵种_战神.bmp",
    ]

    # 自定义下兵间隔（毫秒）
    下兵间隔映射 = {
        "兵种_战神.bmp": 50,
    }


    # 下兵间隔相关常量
    默认下兵间隔 = 50  # 毫秒
    最大波动范围 = 30  # 毫秒
    最大下兵失败次数 = 3
    记录最后下兵位置数量 = 3

    def __init__(self, 上下文: '任务上下文'):
        super().__init__(上下文)
        self.ocr引擎 = 安全OCR引擎()
        self.检测器 = 线程安全YOLO检测器()
        self.模板识别 = 模板匹配引擎()
        self.截图工具 = 截图保存工具()

    def 执行(self, 上下文: 任务上下文) -> bool:
        # 1. 获取并检测目标
        全屏图像 = 上下文.op.获取屏幕图像cv(0, 0, 800, 600)
        检测结果列表 = self.检测器.检测(全屏图像)

        # 2. 筛选有效目标
        有效目标列表 = self.筛选有效目标(上下文, 检测结果列表)

        # 3. 执行下兵流程
        self.执行下兵流程(上下文, 有效目标列表)
        上下文.脚本延时(random.randint(4*1000, 7*1000))
        return True

    def 筛选有效目标(self, 上下文: 任务上下文, 检测结果列表: list) -> list:
        """筛选有效的资源建筑目标

        参数:
            上下文: 任务上下文
            检测结果列表: YOLO检测的原始结果

        返回:
            有效目标列表，每个目标包含中心坐标
        """
        边缘距离限制 = 上下文.数据库.获取机器人设置(上下文.机器人标志).欲进攻资源建筑靠近地图边缘最小比例

        if 边缘距离限制 != 0:
            有效目标列表 = [
                {
                    **片段,
                    '中心坐标': self.计算中心坐标(片段['裁剪坐标'])
                }
                for 片段 in 检测结果列表
                if 片段['类别名称'] in ('金矿', '圣水采集器')
                   and 判断目标点到可进攻边缘距离是否小于设定值(
                    self.计算中心坐标(片段['裁剪坐标']), 80
                )
            ]
        else:
            有效目标列表 = [
                {
                    **片段,
                    '中心坐标': self.计算中心坐标(片段['裁剪坐标'])
                }
                for 片段 in 检测结果列表
                if 片段['类别名称'] in ('金矿', '圣水采集器')
            ]

        上下文.置脚本状态(f"识别到采集器数量 {len(有效目标列表)}")
        return 有效目标列表

    def 执行下兵流程(self, 上下文: 任务上下文, 有效目标列表: list) -> list:
        """执行下兵流程，对所有兵种按顺序下兵

        参数:
            上下文: 任务上下文
            有效目标列表: 筛选后的有效目标列表

        返回:
            最后下兵坐标列表（最多保留最后3个）
        """
        if not 有效目标列表:
            上下文.置脚本状态("没有有效目标，跳过下兵")
            return []

        有效目标数量 = len(有效目标列表)
        目标索引 = 0
        最后下兵坐标列表 = []

        for 兵种路径 in self.兵种模板列表:
            失败次数 = 0
            间隔毫秒 = self.下兵间隔映射.get(兵种路径, None)

            while True:
                当前目标 = 有效目标列表[目标索引]
                目标坐标 = 当前目标['中心坐标']
                类别 = 当前目标['类别名称']

                上一次下兵已成功, 下兵坐标 = self.下兵(上下文, 兵种路径, 目标坐标, 间隔毫秒)

                if not 上一次下兵已成功:
                    失败次数 += 1
                else:
                    # 上下文.置脚本状态(f"对目标 {目标坐标.x},{目标坐标.y} 下兵 {兵种路径}，目标类别为 {类别}")
                    最后下兵坐标列表.append(下兵坐标)
                    if len(最后下兵坐标列表) > self.记录最后下兵位置数量:
                        最后下兵坐标列表.pop(0)

                目标索引 = (目标索引 + 1) % 有效目标数量

                if 失败次数 > self.最大下兵失败次数:
                    break

        return 最后下兵坐标列表


    def 计算中心坐标(self, 裁剪坐标: list[int]) -> 坐标:
        左, 上, 右, 下 = 裁剪坐标
        return 坐标((左 + 右) // 2, (上 + 下) // 2)

    def 选中兵种(self, 上下文: 任务上下文, 兵种: str) -> bool:
        检测区域 = (11, 506, 775, 594)
        屏幕图像 = 上下文.op.获取屏幕图像cv(*检测区域)

        # 模板匹配检测
        是否匹配, 偏移, _ = self.模板识别.执行匹配(屏幕图像, 兵种,相似度阈值=0.73)
        if not 是否匹配:
            #上下文.置脚本状态(f"当前没有可下的{兵种}")
            return False

        偏移x, 偏移y = 偏移
        兵种位置 = (检测区域[0] + 偏移x, 检测区域[1] + 偏移y)

        # 状态检测流程优化
        是否有白框, 白框列表, _ = self.检测白色矩形框(屏幕图像)
        if 是否有白框 and self.判断点是否被白框包裹((偏移x, 偏移y), 白框列表):
            return True  # 已选中状态

        # 可用性检测
        图块区域 = 上下文.op.获取屏幕图像cv(
            兵种位置[0], 兵种位置[1],
            兵种位置[0] + 20, 兵种位置[1] + 20
        )
        if self.是否为灰色图片(图块区域):
            # 上下文.置脚本状态(f"{兵种}已全部下完")
            return False

        # 英雄特殊检测
        # if "英雄" in 兵种:
        #     血条区域 = 上下文.op.获取屏幕图像cv(
        #         兵种位置[0], 497,
        #         兵种位置[0] + 25, 497 + 13
        #     )
        #     if self.是否包含指定颜色_HSV(
        #             血条区域, (80, 214, 5),
        #             色差H=20, 色差S=20, 色差V=20,
        #             最少像素数=40,是否可视化=False
        #     ):
        #         # 上下文.置脚本状态(f"{兵种}已部署")
        #         return False

        # 执行选中操作
        上下文.点击(*兵种位置)
        return True

    def 下兵(self, 上下文: 任务上下文, 兵种路径: str, 中心坐标: 坐标,下兵间隔=None) -> tuple[bool, tuple[int, int] | None]:
        """优化后的下兵方法，增加状态缓存和结果直接返回

        返回: (是否成功, 下兵坐标) 其中下兵坐标为 (x, y) 或 None
        """
        if not self.选中兵种(上下文, 兵种路径):
            return False, None

        下兵点x,下兵点y = self.取可靠下兵点的坐标(中心坐标.x, 中心坐标.y)

        #计算下兵后延时的时间,使用正态分布
        均值 = 100 if 下兵间隔 is None else 下兵间隔
        标准差 = 50
        # 获取一个正态分布的随机数，并四舍五入成整数
        数值 = round(random.gauss(均值, 标准差))
        # 限制范围在 0 到 300 之间
        延时数值 = max(0, min(200, 数值))
        上下文.点击(下兵点x, 下兵点y,延时=延时数值)

        return True, (下兵点x, 下兵点y)


    @staticmethod
    def 是否包含指定颜色_HSV(图像: np.ndarray, 目标RGB: tuple,
                             色差H=10, 色差S=100, 色差V=100,
                             最少像素数=1000, 是否可视化=False) -> bool:

        "H (色相),S (饱和度),V (亮度)表示这三者的偏移的容忍程度"

        # 将图像转换为 HSV
        hsv图像 = cv2.cvtColor(图像, cv2.COLOR_BGR2HSV)

        # RGB → HSV（先转 BGR 再转 HSV）
        目标色_BGR = np.uint8([[list(reversed(目标RGB))]])  # RGB -> BGR
        目标色_HSV = cv2.cvtColor(目标色_BGR, cv2.COLOR_BGR2HSV)[0][0]
        h, s, v = map(int, 目标色_HSV)  # ⚠️ 转成 int 防止溢出

        # 定义 HSV 范围上下限
        下限 = np.array([max(0, h - 色差H), max(0, s - 色差S), max(0, v - 色差V)])
        上限 = np.array([min(179, h + 色差H), min(255, s + 色差S), min(255, v + 色差V)])

        # 掩码提取
        掩码 = cv2.inRange(hsv图像, 下限, 上限)
        匹配像素数 = cv2.countNonZero(掩码)

        #print(f"目标HSV: {目标色_HSV}  匹配像素数: {匹配像素数}")

        if 是否可视化:
            cv2.imshow("原图", 图像)
            cv2.imshow("匹配掩码", 掩码)
            cv2.waitKey(0)
            cv2.destroyAllWindows()

        return 匹配像素数 >= 最少像素数

    @staticmethod
    def 判断点是否被白框包裹(点坐标, 白框列表):
        """
        判断一个点是否被白框包裹

        参数:
            点坐标: (x, y)
            白框列表: [(x1, y1, x2, y2), ...]

        返回:
            是否包裹: bool
            包裹该点的框坐标: (x1, y1, x2, y2) 或 None
        """
        点x, 点y = 点坐标

        for 框 in 白框列表:
            框x1, 框y1, 框x2, 框y2 = 框
            if 框x1 <= 点x <= 框x2 and 框y1 <= 点y <= 框y2:
                return True, 框

        return False, None

    @staticmethod
    def 检测白色矩形框(CV图像, 最小面积=1000, 阈值=200):
        """
        检测图像中的白色矩形框，并返回其坐标

        参数:
            图像路径: cv图像
            最小面积: 忽略小区域
            阈值: 白色提取的二值化阈值

        返回:
            是否检测到: bool
            框坐标列表: [(x1, y1, x2, y2), ...]
            标记图像: 可视化结果图
        """
        #原图 = cv2.imread(图像路径)
        原图=CV图像

        灰度图 = cv2.cvtColor(原图, cv2.COLOR_BGR2GRAY)
        _, 二值图 = cv2.threshold(灰度图, 阈值, 255, cv2.THRESH_BINARY)

        轮廓列表, _ = cv2.findContours(二值图, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        检测到 = False
        框坐标列表 = []

        for 轮廓 in 轮廓列表:
            面积 = cv2.contourArea(轮廓)
            if 面积 < 最小面积:
                continue

            周长 = cv2.arcLength(轮廓, True)
            多边形 = cv2.approxPolyDP(轮廓, 0.02 * 周长, True)

            if len(多边形) == 4:
                x, y, 宽, 高 = cv2.boundingRect(多边形)
                宽高比 = 宽 / 高

                if 0.7 < 宽高比 < 1.3:  # 可根据具体框的形状需求调整
                    检测到 = True
                    x1, y1 = x, y
                    x2, y2 = x + 宽, y + 高
                    框坐标列表.append((x1, y1, x2, y2))
                    cv2.rectangle(原图, (x1, y1), (x2, y2), (0, 255, 0), 2)

        return 检测到, 框坐标列表, 原图

    @staticmethod
    def 是否为灰色图片(CV图像, 偏差阈值=10, 灰色比例阈值=0.9):
        # 读取图片
        图像 =CV图像

        # 获取图像的各通道
        B, G, R = cv2.split(图像)

        # 计算每个像素点的RGB差异是否都小于阈值
        条件1 = np.abs(R - G) < 偏差阈值
        条件2 = np.abs(R - B) < 偏差阈值
        条件3 = np.abs(G - B) < 偏差阈值

        灰色像素掩码 = 条件1 & 条件2 & 条件3

        # 计算灰色像素占比
        灰色像素数量 = np.sum(灰色像素掩码)
        总像素数量 = 图像.shape[0] * 图像.shape[1]
        灰色比例 = 灰色像素数量 / 总像素数量

        return 灰色比例 >= 灰色比例阈值

    def 取可靠下兵点的坐标(self, 攻击目标x: int, 攻击目标y: int) -> Tuple[int, int]:
        进攻方向 = 取进攻方向(坐标(攻击目标x, 攻击目标y))
        取得的坐标 = 取可下兵坐标点(进攻方向, 坐标(攻击目标x, 攻击目标y))
        return 取得的坐标.x, 取得的坐标.y
